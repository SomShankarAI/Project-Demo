Microsoft Windows [Version 10.0.26100.6584]
(c) Microsoft Corporation. All rights reserved.

D:\Git\Python\Project-Demo>D:/Git/Python/Project-Demo/.venv/Scripts/activate.bat

(.venv) D:\Git\Python\Project-Demo>D:/Git/Python/Project-Demo/.venv/Scripts/python.exe d:/Git/Python/Project-Demo/run_server.py
Starting FastAPI server on 127.0.0.1:8000
DEBUG:asyncio:Using proactor: IocpProactor
INFO:     Started server process [20984]
INFO:     Waiting for application startup.
INFO:server_app.main:Starting up and initializing workflow...
DEBUG:mcp.client.streamable_http:Connecting to StreamableHTTP endpoint: http://127.0.0.1:8001/mcp
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCRequest(method='initialize', params={'protocolVersion': '2025-06-18', 'capabilities': {}, 'clientInfo': {'name': 'mcp', 'version': '0.1.0'}}, jsonrpc='2.0', id=0)
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB81997F0>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:19 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'39398d66b57d46678d4f3514241e029d'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
INFO:mcp.client.streamable_http:Received session ID: 39398d66b57d46678d4f3514241e029d
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:mcp.client.streamable_http:SSE message: root=JSONRPCResponse(jsonrpc='2.0', id=0, result={'protocolVersion': '2025-06-18', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': True}, 'resources': {'subscribe': False, 'listChanged': True}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Onboarding MCP Server', 'version': '1.14.0'}})
INFO:mcp.client.streamable_http:Negotiated protocol version: 2025-06-18
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCNotification(method='notifications/initialized', params=None, jsonrpc='2.0')
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB8113C50>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB81C4550>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 202, b'Accepted', [(b'date', b'Fri, 19 Sep 2025 05:39:19 GMT'), (b'server', b'uvicorn'), (b'content-type', b'application/json'), (b'mcp-session-id', b'39398d66b57d46678d4f3514241e029d'), (b'content-length', b'0')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 202 Accepted"
DEBUG:mcp.client.streamable_http:Received 202 Accepted
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:receive_response_body.failed exception=GeneratorExit()
DEBUG:httpcore.http11:response_closed.complete
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:19 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'39398d66b57d46678d4f3514241e029d'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: GET http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:mcp.client.streamable_http:GET SSE connection established
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCRequest(method='tools/list', params=None, jsonrpc='2.0', id=1)
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB81C0C30>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:19 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'39398d66b57d46678d4f3514241e029d'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:mcp.client.streamable_http:SSE message: root=JSONRPCResponse(jsonrpc='2.0', id=1, result={'tools': [{'name': 'get_profile_and_team_name_by_store_id', 'description': 'Get team name and profile name for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing team_name and profile_name', 'inputSchema': {'properties': {'store_id': {'title': 'Store Id', 'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}, 'outputSchema': {'additionalProperties': True, 'type': 'object'}, '_meta': {'_fastmcp': {'tags': []}}}, {'name': 'get_b2b_profiles_and_identities_by_store_id', 'description': 'Get B2B profiles and identities for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing profiles and identities lists', 'inputSchema': {'properties': {'store_id': {'title': 'Store Id', 'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}, 'outputSchema': {'additionalProperties': True, 'type': 'object'}, '_meta': {'_fastmcp': {'tags': []}}}, {'name': 'onboard_user', 'description': 'Start the user onboarding process\n\nArgs:\n    store_id: The store ID\n    team_name: The team name\n    profile_name: The profile name\n    selected_profiles: List of selected B2B profiles\n    selected_identities: List of selected B2B identities\n    \nReturns:\n    Dictionary containing onboarding status and details', 'inputSchema': {'properties': {'store_id': {'title': 'Store Id', 'type': 'string'}, 'team_name': {'title': 'Team Name', 'type': 'string'}, 'profile_name': {'title': 'Profile Name', 'type': 'string'}, 'selected_profiles': {'items': {}, 'title': 'Selected Profiles', 'type': 'array'}, 'selected_identities': {'items': {}, 'title': 'Selected Identities', 'type': 'array'}}, 'required': ['store_id', 'team_name', 'profile_name', 'selected_profiles', 'selected_identities'], 'type': 'object'}, 'outputSchema': {'additionalProperties': True, 'type': 'object'}, '_meta': {'_fastmcp': {'tags': []}}}]})
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB81C2190>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:receive_response_body.failed exception=GeneratorExit()
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:19 GMT'), (b'server', b'uvicorn'), (b'content-type', b'application/json'), (b'mcp-session-id', b'39398d66b57d46678d4f3514241e029d'), (b'content-length', b'0')])
INFO:httpx:HTTP Request: DELETE http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.http11:receive_response_body.failed exception=CancelledError('Cancelled by cancel scope 23fb80d12b0')
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:httpcore.connection:close.complete
INFO:server_app.main:Workflow initialized successfully.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:server_app.workflow:Processing step: collect_store_id
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-63a065f4-f8cc-414c-8d36-7cd057d82bfb', 'json_data': {'messages': [{'content': "\n                        You are a helpfull assistance to help onboarding a new user.                        
           \n                        Try to get StoreId from the user message. If succesfully able to extract StoreId then return a json object with properties 'is_success':'true','storeid':'extracted store id'.\n                        if not able to find any StoreId then prompt the user to provide one. Do not assume any value, always ask the user for more information. Response should be a json object with properties 'is_success':'false','user_promt':'your ask to user'.\n                        ", 'role': 'system'}, {'content': 'need to onboard a customer with StoreId ST254879', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023FB8678AD0>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023FB818BBB0> server_hostname='api.openai.com' timeout=None
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023FB86416D0>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Sep 2025 05:39:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'som-krzwyw'), (b'openai-processing-ms', b'315'), (b'openai-project', b'proj_vNFxSxENFEpwBhfVejwQop5Z'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'864'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199833'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'50ms'), (b'x-request-id', b'req_af09d4c9f75a46189efdfdbb00c5d1af'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=owgLe8yQc4qFCPGzYhSggGJcLED9.Ke7_pXo8S7dnms-1758260397-1.0.1.1-rzpzkCRlrntruboS6DEevHDZEZsaRW4ccjZY1aKLJsjMuB57KR4.FNqTnFg_3TMtTXpU9HJ6gxdXzm2vT2NlFNsBy__kPUuRs_Hd8kxhQcw; path=/; expires=Fri, 19-Sep-25 06:09:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Fl8JrLgYDe54qPmFzOVr8HhIkd9QjLg4EdwDr6wLx2Y-1758260397330-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9816becfdc2bd817-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 19 Sep 2025 05:39:57 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'som-krzwyw'), ('openai-processing-ms', '315'), ('openai-project', 'proj_vNFxSxENFEpwBhfVejwQop5Z'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '864'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199833'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '50ms'), ('x-request-id', 'req_af09d4c9f75a46189efdfdbb00c5d1af'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=owgLe8yQc4qFCPGzYhSggGJcLED9.Ke7_pXo8S7dnms-1758260397-1.0.1.1-rzpzkCRlrntruboS6DEevHDZEZsaRW4ccjZY1aKLJsjMuB57KR4.FNqTnFg_3TMtTXpU9HJ6gxdXzm2vT2NlFNsBy__kPUuRs_Hd8kxhQcw; path=/; expires=Fri, 19-Sep-25 06:09:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Fl8JrLgYDe54qPmFzOVr8HhIkd9QjLg4EdwDr6wLx2Y-1758260397330-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9816becfdc2bd817-BLR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
DEBUG:openai._base_client:request_id: req_af09d4c9f75a46189efdfdbb00c5d1af
DEBUG:server_app.workflow:LLM response: {
    "is_success": "true",
    "storeid": "ST254879"
}
INFO:server_app.workflow:Processing step: fetch_b2b_data
DEBUG:mcp.client.streamable_http:Connecting to StreamableHTTP endpoint: http://127.0.0.1:8001/mcp
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCRequest(method='initialize', params={'protocolVersion': '2025-06-18', 'capabilities': {}, 'clientInfo': {'name': 'mcp', 'version': '0.1.0'}}, jsonrpc='2.0', id=0)
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB868D010>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:56 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
INFO:mcp.client.streamable_http:Received session ID: fda08698250f42b095e0c899f8a08926
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:mcp.client.streamable_http:SSE message: root=JSONRPCResponse(jsonrpc='2.0', id=0, result={'protocolVersion': '2025-06-18', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': True}, 'resources': {'subscribe': False, 'listChanged': True}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Onboarding MCP Server', 'version': '1.14.0'}})
INFO:mcp.client.streamable_http:Negotiated protocol version: 2025-06-18
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCNotification(method='notifications/initialized', params=None, jsonrpc='2.0')
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB8617240>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB8617460>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 202, b'Accepted', [(b'date', b'Fri, 19 Sep 2025 05:39:56 GMT'), (b'server', b'uvicorn'), (b'content-type', b'application/json'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'content-length', b'0')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 202 Accepted"
DEBUG:mcp.client.streamable_http:Received 202 Accepted
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:receive_response_body.failed exception=GeneratorExit()
DEBUG:httpcore.http11:response_closed.complete
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCRequest(method='tools/list', params=None, jsonrpc='2.0', id=1)
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:56 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: GET http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:mcp.client.streamable_http:GET SSE connection established
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB8603550>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:56 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:mcp.client.streamable_http:SSE message: root=JSONRPCResponse(jsonrpc='2.0', id=1, result={'tools': [{'name': 'get_profile_and_team_name_by_store_id', 'description': 'Get team name and profile name for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing team_name and profile_name', 'inputSchema': {'properties': {'store_id': {'title': 'Store Id', 'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}, 'outputSchema': {'additionalProperties': True, 'type': 'object'}, '_meta': {'_fastmcp': {'tags': []}}}, {'name': 'get_b2b_profiles_and_identities_by_store_id', 'description': 'Get B2B profiles and identities for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing profiles and identities lists', 'inputSchema': {'properties': {'store_id': {'title': 'Store Id', 'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}, 'outputSchema': {'additionalProperties': True, 'type': 'object'}, '_meta': {'_fastmcp': {'tags': []}}}, {'name': 'onboard_user', 'description': 'Start the user onboarding process\n\nArgs:\n    store_id: The store ID\n    team_name: The team name\n    profile_name: The profile name\n    selected_profiles: List of selected B2B profiles\n    selected_identities: List of selected B2B identities\n    \nReturns:\n    Dictionary containing onboarding status and details', 'inputSchema': {'properties': {'store_id': {'title': 'Store Id', 'type': 'string'}, 'team_name': {'title': 'Team Name', 'type': 'string'}, 'profile_name': {'title': 'Profile Name', 'type': 'string'}, 'selected_profiles': {'items': {}, 'title': 'Selected Profiles', 'type': 'array'}, 'selected_identities': {'items': {}, 'title': 'Selected Identities', 'type': 'array'}}, 'required': ['store_id', 'team_name', 'profile_name', 'selected_profiles', 'selected_identities'], 'type': 'object'}, 'outputSchema': {'additionalProperties': True, 'type': 'object'}, '_meta': {'_fastmcp': {'tags': []}}}]})
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
[values] {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac')]}
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-2e4b6965-526d-4250-89d8-5c8bbd21bfb0', 'json_data': {'messages': [{'content': '\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1, 'tools': [{'type': 'function', 'function': {'name': 'get_profile_and_team_name_by_store_id', 'description': 'Get team name and profile name for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing team_name and profile_name', 'parameters': {'properties': {'store_id': {'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'get_b2b_profiles_and_identities_by_store_id', 'description': 'Get B2B profiles and identities for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing profiles and identities lists', 'parameters': {'properties': {'store_id': {'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'onboard_user', 'description': 'Start the user onboarding process\n\nArgs:\n    store_id: The store ID\n    team_name: The team name\n    profile_name: The profile name\n    selected_profiles: List of selected B2B profiles\n    selected_identities: List of selected B2B identities\n    \nReturns:\n    Dictionary containing onboarding status and details', 'parameters': {'properties': {'store_id': {'type': 'string'}, 'team_name': {'type': 'string'}, 'profile_name': {'type': 'string'}, 'selected_profiles': {'items': {}, 'type': 'array'}, 'selected_identities': {'items': {}, 'type': 'array'}}, 'required': ['store_id', 'team_name', 'profile_name', 'selected_profiles', 'selected_identities'], 'type': 'object'}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
DEBUG:httpcore.http11:receive_response_body.failed exception=GeneratorExit()
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB86C9850>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023FB81D8230> server_hostname='api.openai.com' timeout=None
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB86AC5F0>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Sep 2025 05:39:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'som-krzwyw'), (b'openai-processing-ms', b'451'), (b'openai-project', b'proj_vNFxSxENFEpwBhfVejwQop5Z'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'780'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199883'), (b'x-ratelimit-reset-requests', b'15.128s'), (b'x-ratelimit-reset-tokens', b'35ms'), (b'x-request-id', b'req_e65478cc6edf494299070c86e1181c10'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3VIvvVjJ2CG3gE5mC8MP0E5eDIS6CbGvpaNavO5gWXw-1758260399-1.0.1.1-wPar9qyh6hnLFAQ8iCXhNfpY3lNYDLUHesFTqTSnRp.9m_8XOmAbwb1XiaR48kOV1_0kP0pBwW4FeK1XoKxPsRdDb51pTd.6jjptXMtVCoI; path=/; expires=Fri, 19-Sep-25 06:09:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=nPGt1dSzZNhA1No42ScFVwrhDNEgEMxm36lkcfc5_rI-1758260399585-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9816bede1ce1d3d4-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 19 Sep 2025 05:39:59 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'som-krzwyw'), ('openai-processing-ms', '451'), ('openai-project', 'proj_vNFxSxENFEpwBhfVejwQop5Z'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '780'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199883'), ('x-ratelimit-reset-requests', '15.128s'), ('x-ratelimit-reset-tokens', '35ms'), ('x-request-id', 'req_e65478cc6edf494299070c86e1181c10'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=3VIvvVjJ2CG3gE5mC8MP0E5eDIS6CbGvpaNavO5gWXw-1758260399-1.0.1.1-wPar9qyh6hnLFAQ8iCXhNfpY3lNYDLUHesFTqTSnRp.9m_8XOmAbwb1XiaR48kOV1_0kP0pBwW4FeK1XoKxPsRdDb51pTd.6jjptXMtVCoI; path=/; expires=Fri, 19-Sep-25 06:09:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=nPGt1dSzZNhA1No42ScFVwrhDNEgEMxm36lkcfc5_rI-1758260399585-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9816bede1ce1d3d4-BLR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
DEBUG:openai._base_client:request_id: req_e65478cc6edf494299070c86e1181c10
[updates] {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}
[values] {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCRequest(method='tools/call', params={'name': 'get_profile_and_team_name_by_store_id', 'arguments': {'store_id': 'ST254879'}}, jsonrpc='2.0', id=2)
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB86F0320>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:58 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:mcp.client.streamable_http:SSE message: root=JSONRPCResponse(jsonrpc='2.0', id=2, result={'content': [{'type': 'text', 'text': '{"team_name":"Echo Group","profile_name":"Advanced Profile"}'}], 'structuredContent': {'team_name': 'Echo Group', 'profile_name': 'Advanced Profile'}, 'isError': False})
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
[updates] {'tools': {'messages': [ToolMessage(content='{"team_name":"Echo Group","profile_name":"Advanced Profile"}', name='get_profile_and_team_name_by_store_id', id='12ccf287-1a0e-4a44-8a27-4eb966707f79', tool_call_id='call_O4JSQRyafsZ4vNF0tWKTdSkw')]}}
[values] {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"team_name":"Echo Group","profile_name":"Advanced Profile"}', name='get_profile_and_team_name_by_store_id', id='12ccf287-1a0e-4a44-8a27-4eb966707f79', tool_call_id='call_O4JSQRyafsZ4vNF0tWKTdSkw')]}
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-2c679443-fbca-45c4-bc67-2a3921a888cd', 'json_data': {'messages': [{'content': '\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'name': 'get_profile_and_team_name_by_store_id', 'arguments': '{"store_id": "ST254879"}'}}]}, {'content': '{"team_name":"Echo Group","profile_name":"Advanced Profile"}', 'role': 'tool', 'tool_call_id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1, 'tools': [{'type': 'function', 'function': {'name': 'get_profile_and_team_name_by_store_id', 'description': 'Get team name and profile name for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing team_name and profile_name', 'parameters': {'properties': {'store_id': {'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'get_b2b_profiles_and_identities_by_store_id', 'description': 'Get B2B profiles and identities for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing profiles and identities lists', 'parameters': {'properties': {'store_id': {'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'onboard_user', 'description': 'Start the user onboarding process\n\nArgs:\n    store_id: The store ID\n    team_name: The team name\n    profile_name: The profile name\n    selected_profiles: List of selected B2B profiles\n    selected_identities: List of selected B2B identities\n    \nReturns:\n    Dictionary containing onboarding status and details', 'parameters': {'properties': {'store_id': {'type': 'string'}, 'team_name': {'type': 'string'}, 'profile_name': {'type': 'string'}, 'selected_profiles': {'items': {}, 'type': 'array'}, 'selected_identities': {'items': {}, 'type': 'array'}}, 'required': ['store_id', 'team_name', 'profile_name', 'selected_profiles', 'selected_identities'], 'type': 'object'}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.failed exception=GeneratorExit()
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Sep 2025 05:40:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'som-krzwyw'), (b'openai-processing-ms', b'512'), (b'openai-project', b'proj_vNFxSxENFEpwBhfVejwQop5Z'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'885'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199866'), (b'x-ratelimit-reset-requests', b'22.201s'), (b'x-ratelimit-reset-tokens', b'40ms'), (b'x-request-id', b'req_e0781427805347db81c3aebe7e53deb7'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9816bee9bd1dd3d4-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 19 Sep 2025 05:40:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'som-krzwyw', 'openai-processing-ms': '512', 'openai-project': 'proj_vNFxSxENFEpwBhfVejwQop5Z', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '885', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199866', 'x-ratelimit-reset-requests': '22.201s', 'x-ratelimit-reset-tokens': '40ms', 'x-request-id': 'req_e0781427805347db81c3aebe7e53deb7', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9816bee9bd1dd3d4-BLR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_e0781427805347db81c3aebe7e53deb7
[updates] {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_b2b_profiles_and_identities_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 418, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8eV1PXrdrIuApOT2VA5YNmUUM7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b67207dd-dcca-4787-8fba-31eb924070e2-0', tool_calls=[{'name': 'get_b2b_profiles_and_identities_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 418, 'output_tokens': 26, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}
[values] {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"team_name":"Echo Group","profile_name":"Advanced Profile"}', name='get_profile_and_team_name_by_store_id', id='12ccf287-1a0e-4a44-8a27-4eb966707f79', tool_call_id='call_O4JSQRyafsZ4vNF0tWKTdSkw'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_b2b_profiles_and_identities_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 418, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8eV1PXrdrIuApOT2VA5YNmUUM7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b67207dd-dcca-4787-8fba-31eb924070e2-0', tool_calls=[{'name': 'get_b2b_profiles_and_identities_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 418, 'output_tokens': 26, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
DEBUG:mcp.client.streamable_http:Sending client message: root=JSONRPCRequest(method='tools/call', params={'name': 'get_b2b_profiles_and_identities_by_store_id', 'arguments': {'store_id': 'ST254879'}}, jsonrpc='2.0', id=3)
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB86D20B0>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:39:59 GMT'), (b'server', b'uvicorn'), (b'cache-control', b'no-cache, no-transform'), (b'connection', b'keep-alive'), (b'content-type', b'text/event-stream'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'x-accel-buffering', b'no'), (b'Transfer-Encoding', b'chunked')])
INFO:httpx:HTTP Request: POST http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:mcp.client.streamable_http:SSE message: root=JSONRPCResponse(jsonrpc='2.0', id=3, result={'content': [{'type': 'text', 'text': '{"profiles":["Healthcare Profile","Finance Profile","Automotive Profile","Real Estate Profile","Non-Profit Profile"],"identities":["Specialist Identity","Analyst Identity","Viewer Identity","Operator Identity","Executive Identity"]}'}], 'structuredContent': {'profiles': ['Healthcare Profile', 'Finance Profile', 'Automotive Profile', 'Real Estate Profile', 'Non-Profit Profile'], 'identities': ['Specialist Identity', 'Analyst Identity', 'Viewer Identity', 'Operator Identity', 'Executive Identity']}, 'isError': False})
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
[updates] {'tools': {'messages': [ToolMessage(content='{"profiles":["Healthcare Profile","Finance Profile","Automotive Profile","Real Estate Profile","Non-Profit Profile"],"identities":["Specialist Identity","Analyst Identity","Viewer Identity","Operator Identity","Executive Identity"]}', name='get_b2b_profiles_and_identities_by_store_id', id='54324a81-e742-4e1d-88ed-bc3298798753', tool_call_id='call_li4AqhnvtiYKuAosHaI4zJzJ')]}}
[values] {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"team_name":"Echo Group","profile_name":"Advanced Profile"}', name='get_profile_and_team_name_by_store_id', id='12ccf287-1a0e-4a44-8a27-4eb966707f79', tool_call_id='call_O4JSQRyafsZ4vNF0tWKTdSkw'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_b2b_profiles_and_identities_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 418, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8eV1PXrdrIuApOT2VA5YNmUUM7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b67207dd-dcca-4787-8fba-31eb924070e2-0', tool_calls=[{'name': 'get_b2b_profiles_and_identities_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 418, 'output_tokens': 26, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"profiles":["Healthcare Profile","Finance Profile","Automotive Profile","Real Estate Profile","Non-Profit Profile"],"identities":["Specialist Identity","Analyst Identity","Viewer Identity","Operator Identity","Executive Identity"]}', name='get_b2b_profiles_and_identities_by_store_id', id='54324a81-e742-4e1d-88ed-bc3298798753', tool_call_id='call_li4AqhnvtiYKuAosHaI4zJzJ')]}
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-24adbe16-1c2e-4c5a-9e7c-c7b78da68d66', 'json_data': {'messages': [{'content': '\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'name': 'get_profile_and_team_name_by_store_id', 'arguments': '{"store_id": "ST254879"}'}}]}, {'content': '{"team_name":"Echo Group","profile_name":"Advanced Profile"}', 'role': 'tool', 'tool_call_id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'function': {'name': 'get_b2b_profiles_and_identities_by_store_id', 'arguments': '{"store_id": "ST254879"}'}}]}, {'content': '{"profiles":["Healthcare Profile","Finance Profile","Automotive Profile","Real Estate Profile","Non-Profit Profile"],"identities":["Specialist Identity","Analyst Identity","Viewer Identity","Operator Identity","Executive Identity"]}', 'role': 'tool', 'tool_call_id': 'call_li4AqhnvtiYKuAosHaI4zJzJ'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1, 'tools': [{'type': 'function', 'function': {'name': 'get_profile_and_team_name_by_store_id', 'description': 'Get team name and profile name for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing team_name and profile_name', 'parameters': {'properties': {'store_id': {'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'get_b2b_profiles_and_identities_by_store_id', 'description': 'Get B2B profiles and identities for a given store ID\n\nArgs:\n    store_id: The store ID to lookup\n    \nReturns:\n    Dictionary containing profiles and identities lists', 'parameters': {'properties': {'store_id': {'type': 'string'}}, 'required': ['store_id'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'onboard_user', 'description': 'Start the user onboarding process\n\nArgs:\n    store_id: The store ID\n    team_name: The team name\n    profile_name: The profile name\n    selected_profiles: List of selected B2B profiles\n    selected_identities: List of selected B2B identities\n    \nReturns:\n    Dictionary containing onboarding status and details', 'parameters': {'properties': {'store_id': {'type': 'string'}, 'team_name': {'type': 'string'}, 'profile_name': {'type': 'string'}, 'selected_profiles': {'items': {}, 'type': 'array'}, 'selected_identities': {'items': {}, 'type': 'array'}}, 'required': ['store_id', 'team_name', 'profile_name', 'selected_profiles', 'selected_identities'], 'type': 'object'}}}]}}
DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.failed exception=GeneratorExit()
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Sep 2025 05:40:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'som-krzwyw'), (b'openai-processing-ms', b'674'), (b'openai-project', b'proj_vNFxSxENFEpwBhfVejwQop5Z'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'708'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199806'), (b'x-ratelimit-reset-requests', b'30.015s'), (b'x-ratelimit-reset-tokens', b'58ms'), (b'x-request-id', b'req_84d89c170c4a45fb9ccf3b388688d3ad'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9816bef3cc35d3d4-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 19 Sep 2025 05:40:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'som-krzwyw', 'openai-processing-ms': '674', 'openai-project': 'proj_vNFxSxENFEpwBhfVejwQop5Z', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '708', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199806', 'x-ratelimit-reset-requests': '30.015s', 'x-ratelimit-reset-tokens': '58ms', 'x-request-id': 'req_84d89c170c4a45fb9ccf3b388688d3ad', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9816bef3cc35d3d4-BLR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG:openai._base_client:request_id: req_84d89c170c4a45fb9ccf3b388688d3ad
[updates] {'agent': {'messages': [AIMessage(content='The data has been successfully fetched. Here is the updated information:\n\n- StoreId: ST254879\n- TeamName: Echo Group\n- ProfileName: Advanced Profile\n- B2BProfiles: Healthcare Profile, Finance Profile, Automotive Profile, Real Estate Profile, Non-Profit Profile\n- B2BIdentities: Specialist Identity, Analyst Identity, Viewer Identity, Operator Identity, Executive Identity', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 504, 'total_tokens': 585, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8fd2w6a6LNIw00J3wzn7prbCrq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53b94d9b-5166-4a51-8d01-b9b66cbb0c69-0', usage_metadata={'input_tokens': 504, 'output_tokens': 81, 'total_tokens': 585, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}
[values] {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"team_name":"Echo Group","profile_name":"Advanced Profile"}', name='get_profile_and_team_name_by_store_id', id='12ccf287-1a0e-4a44-8a27-4eb966707f79', tool_call_id='call_O4JSQRyafsZ4vNF0tWKTdSkw'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_b2b_profiles_and_identities_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 418, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8eV1PXrdrIuApOT2VA5YNmUUM7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b67207dd-dcca-4787-8fba-31eb924070e2-0', tool_calls=[{'name': 'get_b2b_profiles_and_identities_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 418, 'output_tokens': 26, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"profiles":["Healthcare Profile","Finance Profile","Automotive Profile","Real Estate Profile","Non-Profit Profile"],"identities":["Specialist Identity","Analyst Identity","Viewer Identity","Operator Identity","Executive Identity"]}', name='get_b2b_profiles_and_identities_by_store_id', id='54324a81-e742-4e1d-88ed-bc3298798753', tool_call_id='call_li4AqhnvtiYKuAosHaI4zJzJ'), AIMessage(content='The data has been successfully fetched. Here is the updated information:\n\n- StoreId: ST254879\n- TeamName: Echo Group\n- ProfileName: Advanced Profile\n- B2BProfiles: Healthcare Profile, Finance Profile, Automotive Profile, Real Estate Profile, Non-Profit Profile\n- B2BIdentities: Specialist Identity, Analyst Identity, Viewer Identity, Operator Identity, Executive Identity', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 504, 'total_tokens': 585, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8fd2w6a6LNIw00J3wzn7prbCrq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53b94d9b-5166-4a51-8d01-b9b66cbb0c69-0', usage_metadata={'input_tokens': 504, 'output_tokens': 81, 'total_tokens': 585, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
DEBUG:server_app.workflow:Agent response: {'messages': [HumanMessage(content='\n            Current state:\n            - StoreId: ST254879\n            - TeamName: None\n            - ProfileName: None\n            - B2BProfiles: None\n            - B2BIdentities: None\n            Based on StoreId populate TeamaName, ProfileName, B2BProfiles and B2BIdentities using Tools provided. Once done return a json object with properties store_id, team_name, profile_name, b2b_profiles and b2b_identities with the values fetched from Tools.\n        ', additional_kwargs={}, response_metadata={}, id='2264d5c6-09a7-4f02-ae5f-0a072f1da1ac'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_profile_and_team_name_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 368, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8d0QJx7XEB9GpOZHoqiKb6QZ77', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3165b534-bfa9-498c-8f4b-885b971be553-0', tool_calls=[{'name': 'get_profile_and_team_name_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_O4JSQRyafsZ4vNF0tWKTdSkw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 368, 'output_tokens': 23, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"team_name":"Echo Group","profile_name":"Advanced Profile"}', name='get_profile_and_team_name_by_store_id', id='12ccf287-1a0e-4a44-8a27-4eb966707f79', tool_call_id='call_O4JSQRyafsZ4vNF0tWKTdSkw'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'function': {'arguments': '{"store_id":"ST254879"}', 'name': 'get_b2b_profiles_and_identities_by_store_id'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 418, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8eV1PXrdrIuApOT2VA5YNmUUM7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b67207dd-dcca-4787-8fba-31eb924070e2-0', tool_calls=[{'name': 'get_b2b_profiles_and_identities_by_store_id', 'args': {'store_id': 'ST254879'}, 'id': 'call_li4AqhnvtiYKuAosHaI4zJzJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 418, 'output_tokens': 26, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{"profiles":["Healthcare Profile","Finance Profile","Automotive Profile","Real Estate Profile","Non-Profit Profile"],"identities":["Specialist Identity","Analyst Identity","Viewer Identity","Operator Identity","Executive Identity"]}', name='get_b2b_profiles_and_identities_by_store_id', id='54324a81-e742-4e1d-88ed-bc3298798753', tool_call_id='call_li4AqhnvtiYKuAosHaI4zJzJ'), AIMessage(content='The data has been successfully fetched. Here is the updated information:\n\n- StoreId: ST254879\n- TeamName: Echo Group\n- ProfileName: Advanced Profile\n- B2BProfiles: Healthcare Profile, Finance Profile, Automotive Profile, Real Estate Profile, Non-Profit Profile\n- B2BIdentities: Specialist Identity, Analyst Identity, Viewer Identity, Operator Identity, Executive Identity', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 504, 'total_tokens': 585, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CHO8fd2w6a6LNIw00J3wzn7prbCrq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53b94d9b-5166-4a51-8d01-b9b66cbb0c69-0', usage_metadata={'input_tokens': 504, 'output_tokens': 81, 'total_tokens': 585, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=8001 local_address=None timeout=30 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000023FB86D2C10>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Fri, 19 Sep 2025 05:40:01 GMT'), (b'server', b'uvicorn'), (b'content-type', b'application/json'), (b'mcp-session-id', b'fda08698250f42b095e0c899f8a08926'), (b'content-length', b'0')])
INFO:httpx:HTTP Request: DELETE http://127.0.0.1:8001/mcp "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'DELETE']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.http11:receive_response_body.failed exception=CancelledError('Cancelled by cancel scope 23fb85f1b20')
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:httpcore.connection:close.complete
DEBUG:server_app.workflow:Workflow result: {'messages': [HumanMessage(content='need to onboard a customer with StoreId ST254879', additional_kwargs={}, response_metadata={}, id='72b4b050-8f2a-45a1-89af-83290a626f4b')], 'onboarding_state': OnboardingState(store_id='ST254879', team_name=None, profile_name=None, b2b_profiles=None, b2b_identities=None, selected_profiles=None, selected_identities=None, step='fetch_b2b_data')}
INFO:     127.0.0.1:51227 - "POST /chat HTTP/1.1" 200 OK
